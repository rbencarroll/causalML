{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Stochastic Variational Inference (SVI) in Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyro has been designed with particular attention paid to supporting stochastic variational inferences as a general purpose inference algorithm. Let's see how we go about doing variational inference in Pyro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We're going to assume we've already defined our model in Pyro. As a quick reminder, the model is given as a stochastic function `model(*args, **kwargs)`, which, in the general case takes arguments. The different pieces of `model()` are encoded via the mapping.:\n",
    "1. observations <-> `pyro.sample` with the `obs` argument\n",
    "2. latent random variables <-> `pyro.sample`\n",
    "3. parameters <-> `pyro.param`\n",
    "\n",
    "Now let's establish some notation. The model has observations __x__ and latent random variables __z__ as well as parameters θ. It has a joint probability density of the form\n",
    "\n",
    "\\begin{equation}\n",
    "p_{\\theta}(\\mathbf{x}, \\mathbf{z}) = p_{\\theta}(\\mathbf{x}|\\mathbf{z})p_{\\theta}(\\mathbf{z})\n",
    "\\end{equation}\n",
    "\n",
    "We assume that the various probability distributions $p_{i}$, that make up $p_{\\theta}(\\mathbf{x}, \\mathbf{z})$ have the following properties.\n",
    "1. We can sample from each $p_i$\n",
    "2. We can compute the pointwize log pdf of $p_i$\n",
    "3. $p_i$ is differentiable w.r.t. the paramters $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Learning\n",
    "\n",
    "In this context our criterion for learning a good model will be maximizing the log evidence, i.e. we want to find the value of $\\theta$ given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_{max} = \\underset{\\theta}{\\operatorname{arg max}}{\\log p_{\\theta}(\\mathbf{x})}\n",
    "\\end{equation}\n",
    "\n",
    "where the log evidence $\\log p_{\\theta}(\\mathbf{x})$ is given by \n",
    "\n",
    "\\begin{equation}\n",
    "\\log p_{\\theta}(\\mathbf{x}) = \\log \\int d\\mathbf{z} p_{\\theta}(\\mathbf{z})\n",
    "\\end{equation}\n",
    "\n",
    "In the general case this is a double difficult problem. This is because (even for a fixed $\\theta$) the integral over the latent random variables $\\mathbf{z}$ is often intractable. Furthermore, even if we know how to calculate the log evidence for all values of $\\theta$, maximizing the log evidence as a fucntion of $\\theta$ will in general be a difficult non-convex optimization problem.\n",
    "\n",
    "In addition to finding $\\theta_{max}$, we would like to calculate the posterior over the latent variables $\\mathbf{z}$:\n",
    "\n",
    "EQUATION\n",
    "\n",
    "Note that the denominator of this expression is the (usually intractable) evidence. Variational inference offers a scheme for finding $\\theta_{max}$ and computing an approximation to the posterior $p_{\\theta}(\\mathbf{z}|\\mathbf{x})$. Lets see how that works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide\n",
    "The basic idea is that we introduce a parameterized distribution $q_{\\phi}(\\mathbf{z})$ , where $\\phi$ are known as the variational parameters. This distribution is called the variational distribution in much of the literature, and in the context of Pyro it's called the guide. The guide will serve as an approximation to the posterior.\n",
    "\n",
    "Just liek the model, the guide is encoded as a stochastic function `guide()` that contains `pyro.sample` and `pyro.param` statements. It does not contain observed data, since the guide needs to be a properly normalized distribution. Note that Pyro enforces that the `model()` and `guide()` have the same call signature, both callables should take the same arguments.\n",
    "\n",
    "Since the guide is an approximation to the posterior $p_{\\theta_{max}}(z|x)$, the guide needs to provide a valid joint probability density over all the latent random variables in the model. Recall that when random variables are specified in Pyro with the primitive statement `pyro.sample`  the first argument denotes the name of th erandom variable. These names will be used to align the random variables in th emodel and guide. To be very explicity, if the model contains a random variable z_1, then the guide needs to have a matching `sample` statement.\n",
    "\n",
    "The distributions used in the two cases can be different, but the names must line up 1-to-1.\n",
    "\n",
    "Once we've specified a guide, we're ready to proceed to inference. Learning will be set up as an optimization problem where each iteration of training takes a step in $\\theta - \\phi$ space that move the guide closer to the exact posterior. To do this we need to define an appropriate objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELBO\n",
    "\n",
    "A simple derivation yields what we're after: the evidence lower bound. The ELBO which is a function of both $\\theta$ and $\\phi$ is defined as an expectation w.r.t. samples from the guide.\n",
    "\n",
    "ELBO = expectation over guides (log p_theta(x,z) - log q_phi(z))\n",
    "\n",
    "By assumption we can compute the log probabilities inside the expectation. And since the guide is assumed to be a parametric distribution we can sample from, we can compute Monte Carlo estimates of this quantity. Crucially, the ELBO is a lower bound to the log evidence, for all choices of $\\theta$ and $\\phi$ we have that log p_theta(x) >= ELBO\n",
    "\n",
    "So if we tke gradient steps to maximize the ELBO, we will alsob e pushing the log evidence higher in expectation. Furthermore it can be shown that the gap between the ELBO and the log evidence is given by the KL divergence of between the guide and posterior.\n",
    "\n",
    "KL divergence measures closeness between two distributions. For a fixed theta, we move phi to increase ELBO, we decrease the KL divergence, in other words moving the guide toward the posterior. In the general case we take gradient steps in \\theta and \\phi so that the guide and model both move. This optimization problem can be solved for many problems.\n",
    "\n",
    "Highlevel. Define guide, compute gradients of ELBO. Some complications, but they are beyond scope of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SVI` Class\n",
    "\n",
    "In pyro the machinery for doing variational inference is captured in the SVI class. \n",
    "\n",
    "The user needs to provide 3 things. model, guide, and optimizer. We've discussed model and guide above. \n",
    "\n",
    "```python\n",
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Model and guide can be arbitrary stochastic functions, if they satisfy the conditions.\n",
    "\n",
    "some detail that i don't need to repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example (my data)\n",
    "\n",
    "two sided coin, query is the coin fair? prior is that it's a US coin, with some wear. \n",
    "\n",
    "Encode our prior as a beta distribution, Beta(10,10), symmetric peaked at 0.5.\n",
    "\n",
    "some observations are stored in `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (np.random.random(10) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "\n",
    "def model(data):\n",
    "    # define the hyperparameters that control the beta prior\n",
    "    α_0 = torch.tensor(10.)\n",
    "    β_0 = torch.tensor(10.)\n",
    "    # sample f from the beta distribution prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(α_0, β_0))\n",
    "    # loop over the observed data\n",
    "    for i in range(len(data)):\n",
    "        # observe datapoint i using the bernoulli likelihood Bernoulli(f)\n",
    "        # each data point is a realization of the bernoulli idstribution with the fairness specified by f\n",
    "        pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next task is to define a guide. The only requirement is that q(f) should be a probability distribution. Simple choice is to use another Beta distribution. This is the 'right' choice in this case because it the the conjugate of the bernoulli. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(data):\n",
    "    # register the two variational parameters with Pyro\n",
    "    α_q = pyro.param(\"α_q\", torch.tensor(15.), constraint=constraints.positive)\n",
    "    β_q = pyro.param(\"β_q\", torch.tensor(15.), constraint=constraints.positive)\n",
    "    # sample latent_fairness from the distribution Beta(α_q, β_q)\n",
    "    pyro.sample('latent_fairness', dist.Beta(α_q, β_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* names line up exactly\n",
    "* same args\n",
    "* variational params are torch tensors\n",
    "* specify constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.distributions import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "\n",
    "adam_params = {'lr': 0.0005, 'betas': (0.9, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# set up the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 5000\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "based on the data and our prior belief, the fairness of the coin is 0.397 +- 0.087\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# grab the learned variational parameters\n",
    "α_q = pyro.param(\"α_q\").item()\n",
    "β_q = pyro.param(\"β_q\").item()\n",
    "\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = α_q / (α_q + β_q)\n",
    "# compute inferred standard deviation\n",
    "factor = β_q / (α_q * (1.0 + α_q + β_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example (as written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro.distributions as dist\n",
    "\n",
    "n_steps = 2000\n",
    "\n",
    "# enable validation (validate parameters of distributions)\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "# clear the param store \n",
    "pyro.clear_param_store()\n",
    "\n",
    "# create some data with 6 obs. heads and 4 obs. tails.\n",
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.tensor(1.0))\n",
    "for _ in range(4):\n",
    "    data.append(torch.tensor(0.))\n",
    "    \n",
    "def model(data):\n",
    "    alpha0 = torch.tensor(10.)\n",
    "    beta0 = torch.tensor(10.)\n",
    "    f = pyro.sample('latent_fairness', dist.Beta(alpha0, beta0))\n",
    "    for i in range(len(data)):\n",
    "        pyro.sample('obs_{}'.format(i), dist.Bernoulli(f), obs=data[i])\n",
    "\n",
    "def guide(data):\n",
    "    alpha_q = pyro.param('alpha_q', torch.tensor(15.0), constraint=constraints.positive)\n",
    "    beta_q = pyro.param('beta_q', torch.tensor(15.), constraint=constraints.positive)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))\n",
    "    \n",
    "optimizer=Adam({})\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)\n",
    "    if step%100:\n",
    "        print('.', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "based on the data and our prior belief, the fairness of the coin is 0.534 +- 0.090\n"
     ]
    }
   ],
   "source": [
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalML-xeA8SeKA",
   "language": "python",
   "name": "causalml-xea8seka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
